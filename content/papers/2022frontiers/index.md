---
title: "Argument mining as rapid screening tool of COVID-19 literature quality: Preliminary evidence" 
date: 2022-07-18
tags: ["natural language processing", "argument mining", "covid-19", "information retrieval", "scientific literature"]
author: ["Gianfranco Brambilla", "Antonella Rosi", "Francesco Antici", "Andrea Galassi", "Daniele Giansanti", "Fabio Magurano", "Federico Ruggeri", "Paolo Torroni", "Evaristo Cisbani", "Marco Lippi"]
description: "We develop an artificial intelligence system for the analysis of the scientific literature by leveraging on recent developments in the field of Argument Mining." 
summary: "We develop an artificial intelligence system for the analysis of the scientific literature by leveraging on recent developments in the field of Argument Mining." 
cover:
    image: "paper.png"
    alt: "Argument mining as rapid screening tool of COVID-19 literature quality: Preliminary evidence"
    relative: true
editPost:
    URL: "https://github.com/federicoruggeri/hugo-website"
    Text: "Frontiers in Public Health"

---

---

##### Download

+ [Paper](paper.pdf)

---

##### Abstract

Background: The COVID-19 pandemic prompted the scientific community to share timely evidence, also in the form of pre-printed papers, not peer reviewed yet.

Purpose: To develop an artificial intelligence system for the analysis of the scientific literature by leveraging on recent developments in the field of Argument Mining.

Methodology: Scientific quality criteria were borrowed from two selected Cochrane systematic reviews. Four independent reviewers gave a blind evaluation on a 1–5 scale to 40 papers for each review. These scores were matched with the automatic analysis performed by an AM system named MARGOT, which detected claims and supporting evidence for the cited papers. Outcomes were evaluated with inter-rater indices (Cohen's Kappa, Krippendorff's Alpha, s* statistics).

Results: MARGOT performs differently on the two selected Cochrane reviews: the inter-rater indices show a fair-to-moderate agreement of the most relevant MARGOT metrics both with Cochrane and the skilled interval scores, with larger values for one of the two reviews.

Discussion and conclusions: The noted discrepancy could rely on a limitation of the MARGOT system that can be improved; yet, the level of agreement between human reviewers also suggests a different complexity between the two reviews in debating controversial arguments. These preliminary results encourage to expand and deepen the investigation to other topics and a larger number of highly specialized reviewers, to reduce uncertainty in the evaluation process, thus supporting the retraining of AM systems.

---

##### Citation

Gianfranco Brambilla, Antonella Rosi, Francesco Antici, Andrea Galassi, Daniele Giansanti, Fabio Magurano, Federico Ruggeri, Paolo Torroni, Evaristo Cisbani, and Marco Lippi. Argument mining as rapid screening tool of COVID-19 literature quality: Preliminary evidence. Frontiers in Public Health, 10, 2022.

```latex
@article{brambilla-etal-2022-argument-covid,
author={Brambilla, Gianfranco and Rosi, Antonella and Antici, Francesco and Galassi, Andrea and Giansanti, Daniele and Magurano, Fabio and Ruggeri, Federico and Torroni, Paolo and Cisbani, Evaristo and Lippi, Marco},   
title={Argument mining as rapid screening tool of {COVID}-19 literature quality: Preliminary evidence},      
journal={Frontiers in Public Health},      
volume={10},           
year={2022},      
url={https://www.frontiersin.org/articles/10.3389/fpubh.2022.945181},
doi={10.3389/fpubh.2022.945181},      
issn={2296-2565},   
abstract={<sec>BackgroundThe COVID-19 pandemic prompted the scientific community to share timely evidence, also in the form of pre-printed papers, not peer reviewed yet.</sec><sec>PurposeTo develop an artificial intelligence system for the analysis of the scientific literature by leveraging on recent developments in the field of Argument Mining.</sec><sec>MethodologyScientific quality criteria were borrowed from two selected Cochrane systematic reviews. Four independent reviewers gave a blind evaluation on a 1–5 scale to 40 papers for each review. These scores were matched with the automatic analysis performed by an AM system named MARGOT, which detected claims and supporting evidence for the cited papers. Outcomes were evaluated with inter-rater indices (Cohen's Kappa, Krippendorff's Alpha, s<sup>*</sup> statistics).</sec><sec>ResultsMARGOT performs differently on the two selected Cochrane reviews: the inter-rater indices show a fair-to-moderate agreement of the most relevant MARGOT metrics both with Cochrane and the skilled interval scores, with larger values for one of the two reviews.</sec><sec>Discussion and conclusionsThe noted discrepancy could rely on a limitation of the MARGOT system that can be improved; yet, the level of agreement between human reviewers also suggests a different complexity between the two reviews in debating controversial arguments. These preliminary results encourage to expand and deepen the investigation to other topics and a larger number of highly specialized reviewers, to reduce uncertainty in the evaluation process, thus supporting the retraining of AM systems.</sec>}
}
```
