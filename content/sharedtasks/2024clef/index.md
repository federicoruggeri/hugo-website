---
title: "Overview of the CLEF-2024 CheckThat! Lab: Check-Worthiness, Subjectivity, Persuasion, Roles, Authorities, and Adversarial Robustness" 
date: 2024-09-01
tags: ["natural language processing", "shared task", "clef", "subjectivity detection"]
author: ["Alberto Barrón-Cedeño", "Firoj Alam", "Julia Maria Struß", "Preslav Nakov", "Tanmoy Chakraborty", "Tamer Elsayed", "Piotr Przybyła", "Tommaso Caselli", "Giovanni Da San Martino", "Fatima Haouari", "Maram Hasanain", "Chengkai Li", "Jakub Piskorski", "Federico Ruggeri", "Xingyi Song", "Reem Suwaileh"]
description: "We describe the seventh edition of the CheckThat! lab, part of the 2024 Conference and Labs of the Evaluation Forum (CLEF). " 
summary: "We describe the seventh edition of the CheckThat! lab, part of the 2024 Conference and Labs of the Evaluation Forum (CLEF). " 
cover:
    image: "paper.png"
    alt: "Overview of the CLEF-2024 CheckThat! Lab: Check-Worthiness, Subjectivity, Persuasion, Roles, Authorities, and Adversarial Robustness"
    relative: true
editPost:
    URL: "https://github.com/federicoruggeri/hugo-website"
    Text: "CLEF"

---

---

##### Resources

+ [CheckThat! 2025](https://checkthat.gitlab.io/clef2024/)
+ [Paper](paper.pdf)

---

##### Abstract

We describe the seventh edition of the CheckThat! lab, part of the 2024 Conference and Labs of the Evaluation Forum (CLEF). Previous editions of CheckThat! focused on the main tasks of the information verification pipeline: check-worthiness, identifying previously fact-checked claims, supporting evidence retrieval, and claim verification. In this edition, we introduced some new challenges, offering six tasks in fifteen languages (Arabic, Bulgarian, English, Dutch, French, Georgian, German, Greek, Italian, Polish, Portuguese, Russian, Slovene, Spanish, and code-mixed Hindi-English): Task 1 on estimation of check-worthiness (the only task that has been present in all CheckThat! editions), Task 2 on identification of subjectivity (a follow up of the CheckThat! 2023 edition), Task 3 on identification of the use of persuasion techniques (a follow up of SemEval 2023), Task 4 on detection of hero, villain, and victim from memes (a follow up of CONSTRAINT 2022), Task 5 on rumor verification using evidence from authorities (new task), and Task 6 on robustness of credibility assessment with adversarial examples (new task). These are challenging classification and retrieval problems at the document and at the span level, including multilingual and multimodal settings. This year, CheckThat! was one of the most popular labs at CLEF-2024 in terms of team registrations: 130 teams. More than one-third of them (a total of 46) actually participated.

---

##### Citation

Alberto Barrón-Cedeño, Firoj Alam, Julia Maria Struß, Preslav Nakov, Tanmoy Chakraborty, Tamer Elsayed, Piotr Przyby￿a, Tommaso Caselli, Giovanni Da San Martino, Fatima Haouari, et al. Overview of the clef-2024 checkthat! lab: check-worthiness, subjectivity, persuasion, roles, authorities, and adversarial robustness. In International Conference of the Cross-Language Evaluation Forum for European Languages, pages 28–52. Springer, 2024.


```latex
@inproceedings{barron-etal-20240-overview,
  title={Overview of the CLEF-2024 CheckThat! lab: check-worthiness, subjectivity, persuasion, roles, authorities, and adversarial robustness},
  author={Barr{\'o}n-Cede{\~n}o, Alberto and Alam, Firoj and Stru{\ss}, Julia Maria and Nakov, Preslav and Chakraborty, Tanmoy and Elsayed, Tamer and Przyby{\l}a, Piotr and Caselli, Tommaso and Da San Martino, Giovanni and Haouari, Fatima and others},
  booktitle={International Conference of the Cross-Language Evaluation Forum for European Languages},
  pages={28--52},
  year={2024},
  organization={Springer}
}
```
