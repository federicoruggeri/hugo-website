---
title: "Overview of the CLEF-2025 CheckThat! Lab: Subjectivity, fact-checking, claim normalization, and retrieval" 
date: 2025-09-01
tags: ["natural language processing", "shared task", "clef", "subjectivity detection"]
author: [Alberto Barrón-Cedeño, Firoj Alam, Julia Maria Struß, Preslav Nakov, Tanmoy Chakraborty, Tamer Elsayed, Piotr Przybyła, Tommaso Caselli, Giovanni Da San Martino, Fatima Haouari, Maram Hasanain, Chengkai Li, Jakub Piskorski, Federico Ruggeri, Xingyi Song, Reem Suwaileh]
description: "This paper presents the eighth edition of the CheckThat! lab, part of the 2025 Conference and Labs of the Evaluation Forum (CLEF)." 
summary: "This paper presents the eighth edition of the CheckThat! lab, part of the 2025 Conference and Labs of the Evaluation Forum (CLEF)." 
cover:
    image: "paper.png"
    alt: "Overview of the CLEF-2025 CheckThat! Lab: Subjectivity, fact-checking, claim normalization, and retrieval"
    relative: true
editPost:
    URL: "https://github.com/federicoruggeri/hugo-website"
    Text: "CLEF"

---

---

##### Resources

+ [CheckThat! 2025](https://checkthat.gitlab.io/clef2025/)
+ [Paper](paper.pdf)

---

##### Abstract

This paper presents the eighth edition of the CheckThat! lab, part of the 2025 Conference and Labs of the Evaluation Forum (CLEF). As in previous editions of CheckThat!, the lab offers tasks from the core of the verification pipeline, including check-worthiness, identifying previously fact-checked claims, supporting evidence retrieval, and claim verification as well as auxiliary tasks addressing different facets of individual steps of the pipeline: Task 1 is on identification of subjectivity (a follow-up of the CheckThat! 2024 edition), which is related to the check-worthiness task, Task 2 is on claim normalization, Task 3 addresses fact-checking numerical claims, and Task 4 focuses on scientific web discourse processing. These challenging classification and retrieval problems are offered in different mono-, multi- and crosslingual settings covering more than 20 languages. This year, CheckThat! was one of the most popular labs at CLEF-2025 in terms of team registrations: 177 teams registered, almost half of them actually participating (a total of 83 teams) and 54 submitted system description papers.

---

##### Citation

Firoj Alam, Julia Maria Struß, Tanmoy Chakraborty, Stefan Dietze, Salim Hafid, Katerina Korre, Arianna Muti, Preslav Nakov, Federico Ruggeri, Sebastian Schellhammer, et al. Overview of the CLEF-2025 CheckThat! Lab: Subjectivity, fact-checking, claim normalization, and retrieval. In International Conference of the Cross-Language Evaluation Forum for European Languages, pages 199–223. Springer, 2025.


```latex
@inproceedings{alam-etal-2025-overview,
  title={Overview of the {CLEF}-2025 {C}heck{T}hat! {L}ab: {S}ubjectivity, fact-checking, claim normalization, and retrieval},
  author={Alam, Firoj and Stru{\ss}, Julia Maria and Chakraborty, Tanmoy and Dietze, Stefan and Hafid, Salim and Korre, Katerina and Muti, Arianna and Nakov, Preslav and Ruggeri, Federico and Schellhammer, Sebastian and others},
  booktitle={International Conference of the Cross-Language Evaluation Forum for European Languages},
  pages={199--223},
  year={2025},
  organization={Springer}
}
```
